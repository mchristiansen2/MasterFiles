{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d23c3b",
   "metadata": {},
   "source": [
    "# Chapter 12\n",
    "\n",
    "Examples and Exercises from Think Stats, 2nd Edition\n",
    "\n",
    "http://thinkstats2.com\n",
    "\n",
    "Copyright 2016 Allen B. Downey\n",
    "\n",
    "MIT License: https://opensource.org/licenses/MIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7af4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/mj-clean.csv\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import regression\n",
    "import timeseries\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "\n",
    "transactions = pd.read_csv(\"mj-clean.csv\", parse_dates=[5])\n",
    "transactions.head()\n",
    "\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c0d9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GroupByDay(transactions, func=np.mean):\n",
    "    \"\"\"Groups transactions by day and compute the daily mean ppg.\n",
    "\n",
    "    transactions: DataFrame of transactions\n",
    "\n",
    "    returns: DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    grouped = transactions[[\"date\", \"ppg\"]].groupby(\"date\")\n",
    "    daily = grouped.aggregate(func)\n",
    "\n",
    "    daily[\"date\"] = daily.index\n",
    "    start = daily.date[0]\n",
    "    one_year = np.timedelta64(1, \"Y\")\n",
    "    daily[\"years\"] = (daily.date - start) / one_year\n",
    "\n",
    "    return daily\n",
    "\n",
    "def GroupByQualityAndDay(transactions):\n",
    "    \"\"\"Divides transactions by quality and computes mean daily price.\n",
    "\n",
    "    transaction: DataFrame of transactions\n",
    "\n",
    "    returns: map from quality to time series of ppg\n",
    "    \"\"\"\n",
    "    groups = transactions.groupby(\"quality\")\n",
    "    dailies = {}\n",
    "    for name, group in groups:\n",
    "        dailies[name] = GroupByDay(group)\n",
    "\n",
    "    return dailies\n",
    "\n",
    "dailies = GroupByQualityAndDay(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6391a2",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Exercise: 12.1**   The linear model I used in this chapter has the obvious drawback that it is linear, and there is no reason to expect prices to change linearly over time. We can add flexibility to the model by adding a quadratic term, as we did in Section 11.3.\n",
    "\n",
    "Use a quadratic model to fit the time series of daily prices, and use the model to generate predictions. You will have to write a version of `RunLinearModel` that runs that quadratic model, but after that you should be able to reuse code from the chapter to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f23d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunQuadModel(daily):\n",
    "    daily['years2'] = daily.years**2\n",
    "    model = smf.ols(\"ppg ~ years\", data=daily)\n",
    "    results = model.fit()\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c86c8c0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept   13.4   (0)\n",
      "years   -0.708   (3.69e-160)\n",
      "R^2 0.4441\n",
      "Std(ys) 1.096\n",
      "Std(res) 0.8174\n",
      "Writing timeseries11.pdf\n",
      "Writing timeseries11.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PlotQuadModel(daily, name):\n",
    "    model, results = RunQuadModel(daily)\n",
    "    regression.SummarizeResults(results)\n",
    "    timeseries.PlotFittedValues(model, results, label=name)\n",
    "    thinkplot.Save(root='timeseries11', xlabel='years', xlim=[-0.1, 3.8], ylabel='price per gram ($)')\n",
    "PlotQuadModel(daily, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43477df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Exercise: 12.1 ** Write a definition for a class named `SerialCorrelationTest` that extends `HypothesisTest` from Section 9.2. It should take a series and a lag as data, compute the serial correlation of the series with the given lag, and then compute the p-value of the observed correlation.\n",
    "\n",
    "Use this class to test whether the serial correlation in raw price data is statistically significant. Also test the residuals of the linear model and (if you did the previous exercise), the quadratic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e160a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerialCorrelationTest(thinkstats2.HypothesisTest):\n",
    "    def TestStatistic(self, data):\n",
    "        series, lag = data\n",
    "        test_stat = abs(thinkstats2.SerialCorr(series, lag))\n",
    "        return test_stat\n",
    "    def RunModel(self):\n",
    "        series, lag = self.data\n",
    "        permutation = series.reindex(np.random.permutation(series.index))\n",
    "        return permutation, lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b95d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4852293761947381 0.0\n",
      "0.07570473767506267 0.011\n",
      "0.07570473767506267 0.006\n"
     ]
    }
   ],
   "source": [
    "def TestSerialCorrelation(daily):\n",
    "    series = daily.ppg\n",
    "    test = SerialCorrelationTest((series, 1))\n",
    "    pvalue = test.PValue()\n",
    "    print(test.actual, pvalue)\n",
    "    # Quadratic model\n",
    "    _, results = RunQuadModel(daily)\n",
    "    series = results.resid\n",
    "    test = SerialCorrelationTest((series, 1))\n",
    "    pvalue = test.PValue()\n",
    "    print(test.actual, pvalue)\n",
    "    # Linear model\n",
    "    _, results = timeseries.RunLinearModel(daily)\n",
    "    series = results.resid\n",
    "    test = SerialCorrelationTest((series, 1))\n",
    "    pvalue = test.PValue()\n",
    "    print(test.actual, pvalue)\n",
    "TestSerialCorrelation(daily)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
